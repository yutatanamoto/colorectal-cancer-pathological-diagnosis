{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pathlib\n",
    "import tensorflow as tf\n",
    "import tensorflow.io as tfio\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import datasets, layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "NUM_CLASSES = 2\n",
    "RESIZE_TO = 512\n",
    "CROP_TO = 256\n",
    "IMAGE_SIZE = (CROP_TO, CROP_TO)\n",
    "NUM_CHANNELS = 3\n",
    "SCHEDULE_LENGTH = 1000\n",
    "SCHEDULE_BOUNDARIES = [300, 600, 900]\n",
    "BATCH_SIZE = 64\n",
    "SCHEDULE_LENGTH = SCHEDULE_LENGTH * 512 / BATCH_SIZE\n",
    "STEPS_PER_EPOCH = 10\n",
    "lr = 0.03 * BATCH_SIZE / 512 \n",
    "\n",
    "def load_and_preprocess_image(path, target_image_shape=IMAGE_SIZE, num_channnels=NUM_CHANNELS):\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_jpeg(image, channels=num_channnels)\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    image = tf.image.random_brightness(image, 0.2, seed=None)\n",
    "    image = tf.image.random_hue(image, 0.2)\n",
    "#     image = tf.image.resize(image, [RESIZE_TO, RESIZE_TO])\n",
    "#     image = tf.image.random_crop(image, [CROP_TO, CROP_TO, 3])\n",
    "    image = tf.image.resize(image, [CROP_TO, CROP_TO])\n",
    "    image /= 255.0  # normalize to [0,1] range\n",
    "#     image = 2*image-1\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-53dcd45df227>:15: shuffle_and_repeat (from tensorflow.python.data.experimental.ops.shuffle_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.shuffle(buffer_size, seed)` followed by `tf.data.Dataset.repeat(count)`. Static tf.data optimizations will take care of using the fused implementation.\n"
     ]
    }
   ],
   "source": [
    "train_val_data_root = '../dataset_5_512/train'\n",
    "train_val_data_root = pathlib.Path(train_val_data_root)\n",
    "all_image_paths = [str(path) for path in list(train_val_data_root.glob('*/*'))]\n",
    "label_names = sorted(item.name for item in train_val_data_root.glob('*/') if item.is_dir())\n",
    "label_to_index = dict((name, index) for index,name in enumerate(label_names))\n",
    "all_image_labels = [label_to_index[pathlib.Path(path).parent.name] for path in all_image_paths]\n",
    "image_count = len(all_image_paths)\n",
    "image_path_ds = tf.data.Dataset.from_tensor_slices(all_image_paths)\n",
    "image_ds = image_path_ds.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE)\n",
    "label_ds = tf.data.Dataset.from_tensor_slices(tf.cast(all_image_labels, tf.int64))\n",
    "image_label_ds = tf.data.Dataset.zip((image_ds, label_ds))\n",
    "train_pipeline = (\n",
    "    image_label_ds\n",
    "        .cache()\n",
    "        .apply(tf.data.experimental.shuffle_and_repeat(buffer_size=len(all_image_paths)))\n",
    "        .batch(BATCH_SIZE)\n",
    "        .prefetch(buffer_size=AUTOTUNE)\n",
    ")\n",
    "train_steps_per_epoch=tf.math.ceil(len(all_image_paths)/BATCH_SIZE).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_root = '../dataset_5_512/val'\n",
    "test_data_root = pathlib.Path(test_data_root)\n",
    "all_image_paths = [str(path) for path in list(test_data_root.glob('*/*'))]\n",
    "label_names = sorted(item.name for item in test_data_root.glob('*/') if item.is_dir())\n",
    "label_to_index = dict((name, index) for index,name in enumerate(label_names))\n",
    "all_image_labels = [label_to_index[pathlib.Path(path).parent.name] for path in all_image_paths]\n",
    "image_count = len(all_image_paths)\n",
    "image_path_ds = tf.data.Dataset.from_tensor_slices(all_image_paths)\n",
    "image_ds = image_path_ds.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE)\n",
    "label_ds = tf.data.Dataset.from_tensor_slices(tf.cast(all_image_labels, tf.int64))\n",
    "image_label_ds = tf.data.Dataset.zip((image_ds, label_ds))\n",
    "test_pipeline = (image_label_ds\n",
    "                    .cache()\n",
    "                    .apply(tf.data.experimental.shuffle_and_repeat(buffer_size=len(all_image_paths)))\n",
    "                    .batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE))\n",
    "val_steps_per_epoch=tf.math.ceil(len(all_image_paths)/BATCH_SIZE).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = tf.keras.Input(shape=(CROP_TO,CROP_TO,NUM_CHANNELS))\n",
    "vgg16 =  tf.keras.applications.vgg16.VGG16(weights='imagenet', include_top=False, input_tensor=input_tensor)\n",
    "x = vgg16.output\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "x = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "model = tf.keras.Model(inputs=vgg16.input, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.00001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
    ")\n",
    "loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "model.compile(\n",
    "    loss=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "498/498 [==============================] - 222s 446ms/step - loss: 0.1851 - accuracy: 0.9223 - val_loss: 0.1269 - val_accuracy: 0.9500\n",
      "Epoch 2/100\n",
      "498/498 [==============================] - 225s 452ms/step - loss: 0.0915 - accuracy: 0.9652 - val_loss: 0.1221 - val_accuracy: 0.9539\n",
      "Epoch 3/100\n",
      "498/498 [==============================] - 225s 452ms/step - loss: 0.0714 - accuracy: 0.9730 - val_loss: 0.1194 - val_accuracy: 0.9566\n",
      "Epoch 4/100\n",
      "498/498 [==============================] - 224s 450ms/step - loss: 0.0523 - accuracy: 0.9806 - val_loss: 0.2177 - val_accuracy: 0.9311\n",
      "Epoch 5/100\n",
      "498/498 [==============================] - 223s 448ms/step - loss: 0.0418 - accuracy: 0.9847 - val_loss: 0.0934 - val_accuracy: 0.9653\n",
      "Epoch 6/100\n",
      "498/498 [==============================] - 223s 448ms/step - loss: 0.0304 - accuracy: 0.9884 - val_loss: 0.1663 - val_accuracy: 0.9504\n",
      "Epoch 7/100\n",
      "498/498 [==============================] - 223s 448ms/step - loss: 0.0245 - accuracy: 0.9907 - val_loss: 0.1120 - val_accuracy: 0.9628\n",
      "Epoch 8/100\n",
      "498/498 [==============================] - 223s 448ms/step - loss: 0.0210 - accuracy: 0.9926 - val_loss: 0.1291 - val_accuracy: 0.9632\n",
      "Epoch 9/100\n",
      "498/498 [==============================] - 223s 447ms/step - loss: 0.0138 - accuracy: 0.9958 - val_loss: 0.1358 - val_accuracy: 0.9651\n",
      "Epoch 10/100\n",
      "498/498 [==============================] - 223s 447ms/step - loss: 0.0141 - accuracy: 0.9951 - val_loss: 0.1410 - val_accuracy: 0.9632\n",
      "Epoch 11/100\n",
      "498/498 [==============================] - 222s 447ms/step - loss: 0.0097 - accuracy: 0.9970 - val_loss: 0.1723 - val_accuracy: 0.9620\n",
      "Epoch 12/100\n",
      "498/498 [==============================] - 222s 446ms/step - loss: 0.0093 - accuracy: 0.9968 - val_loss: 0.1460 - val_accuracy: 0.9630\n",
      "Epoch 13/100\n",
      "498/498 [==============================] - 223s 447ms/step - loss: 0.0078 - accuracy: 0.9976 - val_loss: 0.1446 - val_accuracy: 0.9647\n",
      "Epoch 14/100\n",
      "498/498 [==============================] - 223s 447ms/step - loss: 0.0125 - accuracy: 0.9959 - val_loss: 0.1422 - val_accuracy: 0.9632\n",
      "Epoch 15/100\n",
      "498/498 [==============================] - 222s 447ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.1703 - val_accuracy: 0.9674\n",
      "Epoch 16/100\n",
      "498/498 [==============================] - 223s 447ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.1790 - val_accuracy: 0.9651\n",
      "Epoch 17/100\n",
      "498/498 [==============================] - 222s 446ms/step - loss: 0.0066 - accuracy: 0.9981 - val_loss: 0.2012 - val_accuracy: 0.9572\n",
      "Epoch 18/100\n",
      "498/498 [==============================] - 222s 447ms/step - loss: 0.0131 - accuracy: 0.9955 - val_loss: 0.1222 - val_accuracy: 0.9626\n",
      "Epoch 19/100\n",
      "498/498 [==============================] - 222s 446ms/step - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.1311 - val_accuracy: 0.9662\n",
      "Epoch 20/100\n",
      "498/498 [==============================] - 222s 446ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.2056 - val_accuracy: 0.9603\n",
      "Epoch 21/100\n",
      "498/498 [==============================] - 222s 446ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.2156 - val_accuracy: 0.9583\n",
      "Epoch 22/100\n",
      "498/498 [==============================] - 222s 446ms/step - loss: 0.0078 - accuracy: 0.9978 - val_loss: 0.1750 - val_accuracy: 0.9639\n",
      "Epoch 23/100\n",
      "498/498 [==============================] - 222s 445ms/step - loss: 0.0095 - accuracy: 0.9976 - val_loss: 0.1921 - val_accuracy: 0.9630\n",
      "Epoch 24/100\n",
      "498/498 [==============================] - 222s 445ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.1692 - val_accuracy: 0.9637\n",
      "Epoch 25/100\n",
      "498/498 [==============================] - 222s 446ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.1861 - val_accuracy: 0.9618\n",
      "Epoch 26/100\n",
      "498/498 [==============================] - 222s 447ms/step - loss: 2.8388e-04 - accuracy: 1.0000 - val_loss: 0.1953 - val_accuracy: 0.9655\n",
      "Epoch 27/100\n",
      "498/498 [==============================] - 222s 446ms/step - loss: 6.5568e-05 - accuracy: 1.0000 - val_loss: 0.1999 - val_accuracy: 0.9676\n",
      "Epoch 28/100\n",
      "498/498 [==============================] - 222s 445ms/step - loss: 4.6055e-05 - accuracy: 1.0000 - val_loss: 0.2072 - val_accuracy: 0.9678\n",
      "Epoch 29/100\n",
      "498/498 [==============================] - 222s 446ms/step - loss: 2.2734e-05 - accuracy: 1.0000 - val_loss: 0.2341 - val_accuracy: 0.9639\n",
      "Epoch 30/100\n",
      "498/498 [==============================] - 222s 446ms/step - loss: 1.4393e-05 - accuracy: 1.0000 - val_loss: 0.2362 - val_accuracy: 0.9666\n",
      "Epoch 31/100\n",
      "498/498 [==============================] - 222s 446ms/step - loss: 1.5063e-05 - accuracy: 1.0000 - val_loss: 0.2557 - val_accuracy: 0.9647\n",
      "Epoch 32/100\n",
      "498/498 [==============================] - 222s 446ms/step - loss: 0.0171 - accuracy: 0.9945 - val_loss: 0.1740 - val_accuracy: 0.9601\n",
      "Epoch 33/100\n",
      "498/498 [==============================] - 222s 445ms/step - loss: 0.0074 - accuracy: 0.9975 - val_loss: 0.1599 - val_accuracy: 0.9620\n",
      "Epoch 34/100\n",
      "498/498 [==============================] - 222s 446ms/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 0.1874 - val_accuracy: 0.9649\n",
      "Epoch 35/100\n",
      "498/498 [==============================] - 222s 446ms/step - loss: 2.3536e-04 - accuracy: 1.0000 - val_loss: 0.1973 - val_accuracy: 0.9653\n",
      "Epoch 36/100\n",
      "498/498 [==============================] - 222s 446ms/step - loss: 7.0003e-05 - accuracy: 1.0000 - val_loss: 0.2153 - val_accuracy: 0.9647\n",
      "Epoch 37/100\n",
      "498/498 [==============================] - 222s 446ms/step - loss: 3.0112e-05 - accuracy: 1.0000 - val_loss: 0.2392 - val_accuracy: 0.9633\n",
      "Epoch 38/100\n",
      "498/498 [==============================] - 222s 446ms/step - loss: 2.1978e-05 - accuracy: 1.0000 - val_loss: 0.2474 - val_accuracy: 0.9632\n",
      "Epoch 39/100\n",
      "498/498 [==============================] - 222s 445ms/step - loss: 1.8358e-05 - accuracy: 1.0000 - val_loss: 0.2566 - val_accuracy: 0.9641\n",
      "Epoch 40/100\n",
      "498/498 [==============================] - 222s 445ms/step - loss: 2.9165e-05 - accuracy: 1.0000 - val_loss: 0.2582 - val_accuracy: 0.9630\n",
      "Epoch 41/100\n",
      "498/498 [==============================] - 222s 445ms/step - loss: 0.0128 - accuracy: 0.9960 - val_loss: 0.1870 - val_accuracy: 0.9597\n",
      "Epoch 42/100\n",
      "498/498 [==============================] - 222s 445ms/step - loss: 5.3353e-04 - accuracy: 0.9998 - val_loss: 0.2320 - val_accuracy: 0.9657\n",
      "Epoch 43/100\n",
      "498/498 [==============================] - 222s 445ms/step - loss: 1.8755e-04 - accuracy: 1.0000 - val_loss: 0.3033 - val_accuracy: 0.9572\n",
      "Epoch 44/100\n",
      "498/498 [==============================] - 222s 446ms/step - loss: 0.0157 - accuracy: 0.9947 - val_loss: 0.1785 - val_accuracy: 0.9616\n",
      "Epoch 45/100\n",
      "498/498 [==============================] - 222s 445ms/step - loss: 3.2690e-04 - accuracy: 1.0000 - val_loss: 0.1847 - val_accuracy: 0.9645\n",
      "Epoch 46/100\n",
      "498/498 [==============================] - 222s 445ms/step - loss: 4.5447e-04 - accuracy: 0.9999 - val_loss: 0.2090 - val_accuracy: 0.9630\n",
      "Epoch 47/100\n",
      "498/498 [==============================] - 222s 446ms/step - loss: 6.4000e-05 - accuracy: 1.0000 - val_loss: 0.2219 - val_accuracy: 0.9659\n",
      "Epoch 48/100\n",
      "498/498 [==============================] - 222s 445ms/step - loss: 3.5938e-05 - accuracy: 1.0000 - val_loss: 0.2427 - val_accuracy: 0.9643\n",
      "Epoch 49/100\n",
      "498/498 [==============================] - 222s 445ms/step - loss: 1.4354e-05 - accuracy: 1.0000 - val_loss: 0.2549 - val_accuracy: 0.9655\n",
      "Epoch 50/100\n",
      "498/498 [==============================] - 222s 445ms/step - loss: 1.7377e-05 - accuracy: 1.0000 - val_loss: 0.2596 - val_accuracy: 0.9645\n",
      "Epoch 51/100\n",
      "498/498 [==============================] - 222s 446ms/step - loss: 8.2609e-06 - accuracy: 1.0000 - val_loss: 0.2771 - val_accuracy: 0.9635\n",
      "Epoch 52/100\n",
      "498/498 [==============================] - 222s 446ms/step - loss: 5.8357e-06 - accuracy: 1.0000 - val_loss: 0.2926 - val_accuracy: 0.9630\n",
      "Epoch 53/100\n",
      "498/498 [==============================] - 222s 445ms/step - loss: 4.0402e-06 - accuracy: 1.0000 - val_loss: 0.2948 - val_accuracy: 0.9632\n",
      "Epoch 54/100\n",
      "498/498 [==============================] - 222s 445ms/step - loss: 3.3430e-06 - accuracy: 1.0000 - val_loss: 0.2924 - val_accuracy: 0.9637\n",
      "Epoch 55/100\n",
      "498/498 [==============================] - 222s 445ms/step - loss: 1.7228e-06 - accuracy: 1.0000 - val_loss: 0.3094 - val_accuracy: 0.9632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "498/498 [==============================] - 222s 445ms/step - loss: 1.6386e-06 - accuracy: 1.0000 - val_loss: 0.3239 - val_accuracy: 0.9632\n",
      "Epoch 57/100\n",
      "498/498 [==============================] - 222s 446ms/step - loss: 0.0159 - accuracy: 0.9948 - val_loss: 0.1852 - val_accuracy: 0.9630\n",
      "Epoch 58/100\n",
      "498/498 [==============================] - 222s 445ms/step - loss: 0.0045 - accuracy: 0.9987 - val_loss: 0.2072 - val_accuracy: 0.9637\n",
      "Epoch 59/100\n",
      "498/498 [==============================] - 222s 446ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.2154 - val_accuracy: 0.9647\n",
      "Epoch 60/100\n",
      "498/498 [==============================] - 222s 445ms/step - loss: 0.0053 - accuracy: 0.9983 - val_loss: 0.1852 - val_accuracy: 0.9628\n",
      "Epoch 61/100\n",
      "498/498 [==============================] - 222s 446ms/step - loss: 2.9509e-04 - accuracy: 0.9999 - val_loss: 0.2144 - val_accuracy: 0.9647\n",
      "Epoch 62/100\n",
      "498/498 [==============================] - 222s 446ms/step - loss: 3.3025e-05 - accuracy: 1.0000 - val_loss: 0.2401 - val_accuracy: 0.9655\n",
      "Epoch 63/100\n",
      "498/498 [==============================] - 222s 446ms/step - loss: 1.6085e-05 - accuracy: 1.0000 - val_loss: 0.2483 - val_accuracy: 0.9651\n",
      "Epoch 64/100\n",
      "498/498 [==============================] - 222s 446ms/step - loss: 1.2297e-05 - accuracy: 1.0000 - val_loss: 0.2604 - val_accuracy: 0.9655\n",
      "Epoch 65/100\n",
      "498/498 [==============================] - 222s 445ms/step - loss: 6.9672e-06 - accuracy: 1.0000 - val_loss: 0.2675 - val_accuracy: 0.9659\n",
      "Epoch 66/100\n",
      "498/498 [==============================] - 222s 445ms/step - loss: 6.5716e-06 - accuracy: 1.0000 - val_loss: 0.2846 - val_accuracy: 0.9660\n",
      "Epoch 67/100\n",
      "498/498 [==============================] - 222s 446ms/step - loss: 4.1002e-06 - accuracy: 1.0000 - val_loss: 0.2849 - val_accuracy: 0.9657\n",
      "Epoch 68/100\n",
      "498/498 [==============================] - 222s 445ms/step - loss: 3.2833e-06 - accuracy: 1.0000 - val_loss: 0.2924 - val_accuracy: 0.9660\n",
      "Epoch 69/100\n",
      "498/498 [==============================] - 222s 446ms/step - loss: 3.5936e-06 - accuracy: 1.0000 - val_loss: 0.3203 - val_accuracy: 0.9641\n",
      "Epoch 70/100\n",
      "498/498 [==============================] - 222s 446ms/step - loss: 2.2140e-06 - accuracy: 1.0000 - val_loss: 0.3091 - val_accuracy: 0.9659\n",
      "Epoch 71/100\n",
      "498/498 [==============================] - 222s 446ms/step - loss: 1.8440e-06 - accuracy: 1.0000 - val_loss: 0.3192 - val_accuracy: 0.9647\n",
      "Epoch 72/100\n",
      "498/498 [==============================] - 222s 445ms/step - loss: 1.1493e-06 - accuracy: 1.0000 - val_loss: 0.3279 - val_accuracy: 0.9655\n",
      "Epoch 73/100\n",
      "498/498 [==============================] - 222s 445ms/step - loss: 7.8323e-07 - accuracy: 1.0000 - val_loss: 0.3363 - val_accuracy: 0.9657\n",
      "Epoch 74/100\n",
      "498/498 [==============================] - 222s 446ms/step - loss: 6.3674e-07 - accuracy: 1.0000 - val_loss: 0.3547 - val_accuracy: 0.9653\n",
      "Epoch 75/100\n",
      "498/498 [==============================] - 222s 446ms/step - loss: 0.0158 - accuracy: 0.9948 - val_loss: 0.1387 - val_accuracy: 0.9657\n",
      "Epoch 76/100\n",
      "498/498 [==============================] - 222s 446ms/step - loss: 0.0049 - accuracy: 0.9982 - val_loss: 0.2098 - val_accuracy: 0.9649\n",
      "Epoch 77/100\n",
      "498/498 [==============================] - 222s 446ms/step - loss: 9.5063e-04 - accuracy: 0.9998 - val_loss: 0.2114 - val_accuracy: 0.9647\n",
      "Epoch 78/100\n",
      "498/498 [==============================] - 221s 445ms/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.1724 - val_accuracy: 0.9649\n",
      "Epoch 79/100\n",
      "498/498 [==============================] - 222s 445ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.2028 - val_accuracy: 0.9647\n",
      "Epoch 80/100\n",
      "498/498 [==============================] - 222s 445ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.2190 - val_accuracy: 0.9655\n",
      "Epoch 81/100\n",
      "498/498 [==============================] - 222s 445ms/step - loss: 5.9697e-04 - accuracy: 0.9998 - val_loss: 0.2290 - val_accuracy: 0.9657\n",
      "Epoch 82/100\n",
      "498/498 [==============================] - 222s 445ms/step - loss: 1.9222e-05 - accuracy: 1.0000 - val_loss: 0.2538 - val_accuracy: 0.9668\n",
      "Epoch 83/100\n",
      "498/498 [==============================] - 222s 445ms/step - loss: 1.2457e-05 - accuracy: 1.0000 - val_loss: 0.2573 - val_accuracy: 0.9680\n",
      "Epoch 84/100\n",
      "498/498 [==============================] - 222s 445ms/step - loss: 7.3842e-06 - accuracy: 1.0000 - val_loss: 0.2681 - val_accuracy: 0.9676\n",
      "Epoch 85/100\n",
      "498/498 [==============================] - 222s 445ms/step - loss: 5.9527e-06 - accuracy: 1.0000 - val_loss: 0.2738 - val_accuracy: 0.9674\n",
      "Epoch 86/100\n",
      "498/498 [==============================] - 222s 445ms/step - loss: 5.1478e-06 - accuracy: 1.0000 - val_loss: 0.2648 - val_accuracy: 0.9693\n",
      "Epoch 87/100\n",
      "498/498 [==============================] - 222s 446ms/step - loss: 3.7082e-06 - accuracy: 1.0000 - val_loss: 0.2817 - val_accuracy: 0.9676\n",
      "Epoch 88/100\n",
      "498/498 [==============================] - 222s 445ms/step - loss: 3.0372e-06 - accuracy: 1.0000 - val_loss: 0.2865 - val_accuracy: 0.9682\n",
      "Epoch 89/100\n",
      "498/498 [==============================] - 221s 444ms/step - loss: 2.8427e-06 - accuracy: 1.0000 - val_loss: 0.3001 - val_accuracy: 0.9676\n",
      "Epoch 90/100\n",
      "498/498 [==============================] - 222s 446ms/step - loss: 1.6380e-06 - accuracy: 1.0000 - val_loss: 0.3119 - val_accuracy: 0.9676\n",
      "Epoch 91/100\n",
      "498/498 [==============================] - 222s 445ms/step - loss: 1.1245e-06 - accuracy: 1.0000 - val_loss: 0.3182 - val_accuracy: 0.9676\n",
      "Epoch 92/100\n",
      "498/498 [==============================] - 222s 445ms/step - loss: 9.6004e-07 - accuracy: 1.0000 - val_loss: 0.3247 - val_accuracy: 0.9682\n",
      "Epoch 93/100\n",
      "498/498 [==============================] - 222s 445ms/step - loss: 6.8003e-07 - accuracy: 1.0000 - val_loss: 0.3363 - val_accuracy: 0.9674\n",
      "Epoch 94/100\n",
      "498/498 [==============================] - 222s 446ms/step - loss: 6.0568e-07 - accuracy: 1.0000 - val_loss: 0.3402 - val_accuracy: 0.9682\n",
      "Epoch 95/100\n",
      "498/498 [==============================] - 222s 446ms/step - loss: 4.3832e-07 - accuracy: 1.0000 - val_loss: 0.3511 - val_accuracy: 0.9678\n",
      "Epoch 96/100\n",
      "498/498 [==============================] - 222s 445ms/step - loss: 2.8938e-07 - accuracy: 1.0000 - val_loss: 0.3682 - val_accuracy: 0.9678\n",
      "Epoch 97/100\n",
      "498/498 [==============================] - 222s 445ms/step - loss: 2.9559e-07 - accuracy: 1.0000 - val_loss: 0.3739 - val_accuracy: 0.9678\n",
      "Epoch 98/100\n",
      "498/498 [==============================] - 222s 446ms/step - loss: 3.3487e-07 - accuracy: 1.0000 - val_loss: 0.3609 - val_accuracy: 0.9689\n",
      "Epoch 99/100\n",
      "498/498 [==============================] - 222s 445ms/step - loss: 0.0120 - accuracy: 0.9960 - val_loss: 0.2096 - val_accuracy: 0.9558\n",
      "Epoch 100/100\n",
      "498/498 [==============================] - 222s 446ms/step - loss: 0.0060 - accuracy: 0.9980 - val_loss: 0.1946 - val_accuracy: 0.9639\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_pipeline, \n",
    "    epochs=100, \n",
    "    steps_per_epoch=train_steps_per_epoch, \n",
    "    validation_data=test_pipeline, \n",
    "    validation_steps=val_steps_per_epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
